{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "daeab713",
   "metadata": {},
   "source": [
    "This script was inspired by a comment I found:\n",
    "\n",
    "PIC\n",
    "\n",
    "Also search shows that this problem is actual\n",
    "\n",
    "https://www.gov.uk/government/news/uk-exposes-sick-russian-troll-factory-plaguing-social-media-with-kremlin-propaganda - UK exposes sick Russian troll factory plaguing social media with Kremlin propaganda\n",
    "\n",
    "#### Background\n",
    "**Key findings include**\n",
    "<ul>\n",
    "  <li>a new troll farm that is seeking to guide and ‘brigade’ a wider network of supporters and sympathisers to engage in targeted trolling behaviours</li>\n",
    "  <li>this information operation and its associated targeted trolling activities are being directed at senior international politicians and international media outlets</li>\n",
    "  <li>traces of the operation have been detected across eight social media platforms including Telegram, Twitter, Facebook and TikTok</li>\n",
    "  <li>key tactical innovations of the operational methodology include the use of commenting behaviours, use of VPNs and deliberate amplification of ‘organic’ content supporting the Kremlin’s position. All of these methods help to avoid detection and interception by social media platforms</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "**Troll tactics**\n",
    "\n",
    "<ul>\n",
    "<li>calling on subscribers to target the social media profiles of opponents and Kremlin critics, including prominent politicians and world leaders, and spam them with pro-Kremlin comments</li>\n",
    "<li>asking them to turn on VPNs and spam the comments sections of specific links to Instagram, YouTube, and Telegram</li>\n",
    "<li>focusing activity on posting comments, rather than authoring original content – a tactic likely to decrease the risks of being detected by social media platforms for engaging in coordinated inauthentic behaviour and/or harmful content</li>\n",
    "<li>searching for ‘organic content’ posted by genuine users coherent with the lines they want to push, and then working to amplify these messages, in order that such views are distorted as the norm. This means that, provided the content they post is not too offensive, they are unlikely to be subject to de-platforming interventions</li>\n",
    "</ul>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "828b38c4",
   "metadata": {},
   "source": [
    "### Source data\n",
    "The initial data set contains parsing (partial, full) of 1500 telegram channels from Mainly contains Russian-language and Ukrainian-language channels. \n",
    "\n",
    "It was created for studying: <ul>\n",
    "<li>hate speech</li>\n",
    "<li>Internet trolll </li>\n",
    "<li>bot farms detection</li>\n",
    "<li>work with text corpus</li>\n",
    "</ul>\n",
    "\n",
    "\n",
    "Statistics:<ul>\n",
    "<li>channels</li>\n",
    "<li>unique users</li>\n",
    "<li>posts</li>\n",
    "<li>comments</li>  \n",
    "</ul>    \n",
    "    \n",
    "To start using, you need to download the data from the link (uTorrent):\n",
    "magnet:?xt=urn:btih:b3c00c5532e34c400a78a287634cf99b49907c47\n",
    "\n",
    "Or use .torrent file Telegram_reader_archive_snapshot_2023_02_19.rar.torrent\n",
    "\n",
    "Then unzip the files to the data directory. The jobs.csv file must be in the same directory as the script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b53c47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74ceef0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_jobs = ['channel', 'date', 'priority', 'min_last_id', 'max_last_id', 'full','channel_id']\n",
    "\n",
    "columns_chats = ['id', 'title', 'date','username', 'participants_count',\n",
    "'creator', 'left', 'broadcast', 'verified', 'megagroup',\n",
    " 'restricted', 'signatures', 'min', 'scam', 'has_link', 'has_geo',\n",
    " 'slowmode_enabled', 'call_active', 'call_not_empty', 'fake', 'gigagroup',\n",
    " 'noforwards', 'join_to_send', 'join_request', 'forum']\n",
    "\n",
    "columns_messages = ['id', 'channel_id', 'date', 'out', 'message','views', 'forwards', 'mentioned', \n",
    "                    'replies', 'edit_date',\n",
    "                    'total_emoji', 'positive_emoji', 'negative_emoji',\n",
    "                    'media_unread', 'silent', 'post', 'from_scheduled', 'legacy',\n",
    "'edit_hide', 'pinned', 'noforwards', 'from_id', 'fwd_from', 'via_bot_id', 'reply_to', 'post_author',\n",
    "'grouped_id',  'mention',\n",
    "                   'fwd_from_date','fwd_from_channel_id','fwd_from_from_name',\n",
    "                    'fwd_from_channel_post','fwd_from_post_author']\n",
    "\n",
    "columns_comments =  ['id', 'channel_id', 'message_id', 'user_id', 'date', 'message', 'out', 'mentioned', 'media_unread',\n",
    " 'silent', 'post', 'from_scheduled', 'legacy', 'edit_hide', 'pinned', 'noforwards', 'fwd_from',\n",
    " 'via_bot_id', 'reply_to_msg_id', 'reply_to_scheduled', 'forum_topic', 'reply_to_peer_id',\n",
    " 'reply_to_top_id', 'reply_markup', 'views', 'forwards', 'replies', 'edit_date', 'post_author',\n",
    " 'grouped_id', 'reactions', 'ttl_period',   ]\n",
    "\n",
    "columns_users = [ 'id', 'access_hash', 'first_name', 'last_name', 'username', 'phone', 'status', 'was_online', \n",
    " 'expires', 'bot_info_version', 'bot_inline_placeholder', 'lang_code', 'emoji_status', 'is_self',\n",
    " 'contact', 'mutual_contact', 'deleted', 'bot', 'bot_chat_history', 'bot_nochats', 'verified', 'restricted',\n",
    " 'min', 'bot_inline_geo', 'support', 'scam', 'apply_min_photo', 'fake', 'bot_attach_menu', 'premium',\n",
    " 'attach_menu_enabled',    \n",
    "\n",
    "]\n",
    "\n",
    "columns_links = ['url', 'title', 'mention', 'date', 'message_id', 'channel_id', 'username']\n",
    "columns_mentions = ['mention', 'message_id', 'channel_id', 'date', 'username', ]\n",
    "\n",
    "columns_black_list = ['channel']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87e7b0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import os\n",
    "# import warnings\n",
    "# warnings.simplefilter(\"ignore\", UserWarning)\n",
    "\n",
    "from warnings import simplefilter\n",
    "simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.display.float_format = '{:.0f}'.format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "023c7269",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    path = '..\\\\Telegram_reader\\\\'\n",
    "    f = open(\"path.txt\", \"r\")\n",
    "    path = f.read()\n",
    "except:\n",
    "    path = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f2bb03",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import socket\n",
    "# socket.gethostname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8a4c508c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'..\\\\\\\\Telegram_reader\\\\\\\\'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0603eff",
   "metadata": {},
   "source": [
    "### Top users\n",
    "Simple statistics\n",
    "\n",
    "Users who left a lot of comments are suspected of being bots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23cdc27a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 ugolokz\n",
      "1 WCIOMofficial\n",
      "2 ASWman\n",
      "3 foxandraven\n",
      "4 rstv01\n",
      "5 elpicahielo\n",
      "6 oneterrikon\n",
      "7 NeBrigada\n",
      "8 ssignl\n",
      "9 smak_media\n",
      "10 ntvnews\n",
      "11 spravedlivo\n",
      "12 porubezhye\n",
      "13 news_sev\n",
      "14 patricklancasternewstoday\n",
      "15 retro_music_knyga\n",
      "16 posidimobsudim\n",
      "17 tv360\n",
      "18 olen_nn\n",
      "19 nzdnipro\n",
      "20 mosrutop\n",
      "21 RWMaloneMD\n",
      "22 nic_and_mike\n",
      "23 regdurdom\n",
      "24 next_stop_by\n",
      "25 NKavkazsky\n",
      "26 rqnst\n",
      "27 svoborus\n",
      "28 go338\n",
      "29 TyskNIP\n",
      "30 nevrotique\n",
      "31 wingsofwar\n",
      "32 pfci_grants\n",
      "33 dbaturin\n",
      "34 bunker_polit\n",
      "35 politsputnik\n",
      "36 minjust_dnr\n",
      "37 tplviv\n",
      "38 sakeritalianotizie\n",
      "39 tihyidon\n",
      "40 moscowtimes_ru\n",
      "41 guardwhite\n",
      "42 u_renovate\n",
      "43 Gryshyna_channel\n",
      "44 Nevrotique\n",
      "45 flagshtok\n",
      "46 vladimirbidyovka\n",
      "47 EvPanina\n",
      "48 vesti_izdyrki\n",
      "49 nemchinovoleh\n",
      "50 IvanDzuban\n",
      "51 emigriceps\n",
      "52 hyzyl\n",
      "53 apasov_ua\n",
      "54 yaremshooter\n",
      "55 vatnoeboloto\n",
      "56 zradaperemoga\n",
      "57 yapnews\n",
      "58 sevstory\n",
      "59 official_moscow\n",
      "60 martynov2021\n",
      "61 belarusian_history\n",
      "62 Ze_News_Ukraine\n",
      "63 peremogi\n",
      "64 imaguru\n",
      "65 protest_kuzbass_chat\n",
      "66 all_russians_should_die\n",
      "67 rossotrudnichestvo\n",
      "68 BaykarTech\n",
      "69 rosich_admin\n",
      "70 kompleks_etalon\n",
      "71 drmyasnikov\n",
      "72 mysly\n",
      "73 chekhov_life\n",
      "74 ibarabanch\n",
      "75 mediatech\n",
      "76 shodbelarus\n",
      "77 slutsky_l\n",
      "78 sanctionstimes\n",
      "79 kachuratut\n",
      "80 shevchenkorostovprizrak\n",
      "81 iarexru\n",
      "82 HouseOfCardsRussia\n",
      "83 politteh\n",
      "84 aptekaN666\n",
      "85 reformby\n",
      "86 mil_by\n",
      "87 peresmeshnitsaS\n",
      "88 Politjoystic_opros\n",
      "89 vprorok\n",
      "90 BYagaVS\n",
      "91 beria_zvonit\n",
      "92 cumatru\n",
      "93 hahaby\n",
      "94 forstrategy\n",
      "95 LogicaSocialis\n",
      "96 ia_steklomoy\n",
      "97 vatfor\n",
      "98 racumd\n",
      "99 seakap\n",
      "100 yoba_m\n",
      "101 Ivkolive\n",
      "102 expressby\n",
      "103 Silver1863bot\n",
      "104 dancingrussians\n",
      "105 russianosint\n",
      "106 Pavlova_Maria_live\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df_gr = pd.DataFrame(columns = ['user_id','channel_id','date_min','date_max','count'])\n",
    "\n",
    "\n",
    "df_jobs = pd.read_csv(path+'jobs.csv', usecols = columns_jobs)\n",
    "for job_idx in range(df_jobs.shape[0]):\n",
    "    channel     = df_jobs.iloc[job_idx].channel\n",
    "    print(job_idx, channel)\n",
    "    try:\n",
    "        df_comments_all = pd.read_csv(path+'data\\\\'+channel+'\\\\'+'df_comments_all.csv')\n",
    "        df_comments_all = df_comments_all.rename({'id':'comment_id'}, axis = 1)\n",
    "        df_comments_all = df_comments_all.drop(['Unnamed: 0','Unnamed: 1'], axis=1, errors='ignore')\n",
    "    except:\n",
    "        df_comments_all = pd.DataFrame(columns = columns_comments)\n",
    "        df_comments_all = df_comments_all.rename({'id':'comment_id'}, axis = 1)    \n",
    "        \n",
    "#     try:\n",
    "#         df_users_all = pd.read_csv(path+'data\\\\'+channel+'\\\\'+'df_users_all.csv')\n",
    "#         df_users_all = df_users_all.rename({'id':'user_id'}, axis = 1) \n",
    "#         df_users_all = df_users_all.drop(['Unnamed: 0','Unnamed: 1'], axis=1, errors='ignore')\n",
    "#     except:\n",
    "#         df_users_all    = pd.DataFrame(columns = columns_users)\n",
    "#         df_users_all    = df_users_all.rename({'id':'user_id'}, axis = 1)  \n",
    "#     try:\n",
    "#         df_messages_all = pd.read_csv(path+'data\\\\'+channel+'\\\\'+'df_messages_all.csv')\n",
    "#         df_messages_all = df_messages_all.rename({'id':'message_id'}, axis = 1)\n",
    "#         df_messages_all = df_messages_all.drop(['Unnamed: 0','Unnamed: 1'], axis=1, errors='ignore')\n",
    "#     except:\n",
    "#         df_messages_all = pd.DataFrame(columns = columns_messages)\n",
    "#         df_messages_all = df_messages_all.rename({'id':'message_id'}, axis = 1)\n",
    "#     try:\n",
    "#         df_chats_all = pd.read_csv(path+'data\\\\'+channel+'\\\\'+'df_chats_all.csv')\n",
    "#         df_chats_all = df_chats_all.rename({'id':'chat_id'}, axis = 1)\n",
    "#         df_chats_all = df_chats_all.drop(['Unnamed: 0','Unnamed: 1'], axis=1, errors='ignore')\n",
    "#     except:\n",
    "#         df_chats_all    = pd.DataFrame(columns = columns_chats)\n",
    "#         df_chats_all    = df_chats_all.rename({'id':'chat_id'}, axis = 1)       \n",
    "    if df_comments_all.shape[0] > 1:\n",
    "        df_gr2 = df_comments_all.groupby(['user_id','channel_id']).agg({'date':['min','max'],\n",
    "                                                                        'message_id':'count'}).reset_index()\n",
    "        df_gr2.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_gr2.columns] \n",
    "        df_gr2.columns = ['user_id','channel_id','date_min','date_max','count']\n",
    "        df_gr2['date_min'] = pd.to_datetime(df_gr2['date_min']) \n",
    "        df_gr2['date_max'] = pd.to_datetime(df_gr2['date_max']) \n",
    "        df_gr2['delta'] = df_gr2['date_max'] - df_gr2['date_min']\n",
    "        df_gr2['freq'] = df_gr2['delta'] / df_gr2['count']\n",
    "\n",
    "        df_gr = pd.concat([df_gr, df_gr2], ignore_index = False)\n",
    "    \n",
    "df_gr = pd.merge(df_gr, df_jobs, how = 'left', on = 'channel_id')\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9993ea48",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr.head() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39237058",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a822d622",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr3 = df_gr.groupby(['user_id']).agg({'date_min':['min'],'date_max':['max'],\n",
    "                        'channel_id':'count','count':'sum'}).reset_index()\n",
    "df_gr3.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in df_gr3.columns] \n",
    "df_gr3.columns = ['user_id','date_min','date_max','channel_count','count']\n",
    "df_gr3['date_min'] = pd.to_datetime(df_gr3['date_min']) \n",
    "df_gr3['date_max'] = pd.to_datetime(df_gr3['date_max']) \n",
    "df_gr3['delta'] = df_gr3['date_max'] - df_gr3['date_min']\n",
    "df_gr3['freq'] = df_gr3['delta'] / df_gr3['count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22fcf99d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_gr3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31073ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr3.sort_values(by=['channel_count','count'], ascending = False).head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "906564a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr3[df_gr3['count']>10].sort_values(by=['freq'], ascending = True).head(20)\n",
    "# 5121760196\n",
    "# 5292993834\n",
    "# 1726360180"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "138c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_gr[df_gr.user_id == 2129783438]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c55830",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5ae2b9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "user_id = 1308921323  # Example of agressive user\n",
    "\n",
    "df_gr_user = df_gr[df_gr.user_id == user_id]\n",
    "for channel in df_gr_user.channel.unique():\n",
    "    \n",
    "# df_jobs = pd.read_csv(path+'jobs.csv', usecols = columns_jobs)\n",
    "# for job_idx in range(df_jobs.shape[0]):\n",
    "#     channel     = df_jobs.iloc[job_idx].channel\n",
    "    \n",
    "    try:\n",
    "        df_comments_all = pd.read_csv(path+'data\\\\'+channel+'\\\\'+'df_comments_all.csv')\n",
    "        df_comments_all = df_comments_all.rename({'id':'comment_id'}, axis = 1)\n",
    "        df_comments_all = df_comments_all.drop(['Unnamed: 0','Unnamed: 1'], axis=1, errors='ignore')\n",
    "    except:\n",
    "        df_comments_all = pd.DataFrame(columns = columns_comments)\n",
    "        df_comments_all = df_comments_all.rename({'id':'comment_id'}, axis = 1) \n",
    "    df_comments_all = df_comments_all[df_comments_all.user_id == user_id]    \n",
    "    if df_comments_all.shape[0] > 0:\n",
    "        print(job_idx, channel)\n",
    "        print(list(df_comments_all.message))\n",
    "#         break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24892981",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
